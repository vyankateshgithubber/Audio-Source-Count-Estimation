{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MajorProject1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ARXpWndQO2PhRmjfO0PrXPfjujZxFCXU",
      "authorship_tag": "ABX9TyOhi2GdpcmR+FcJkjkmWePl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vyankateshgithubber/Audio-Source-Count-Estimation/blob/working/MajorProject1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4rImvrx7kwz"
      },
      "source": [
        "!pip install wavefile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy.core.fromnumeric import size\n",
        "from scipy.io import loadmat\n",
        "from scipy.io.wavfile import write\n",
        "import wavefile\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def plot(h1,s1,convolved_speech_data1,h2,s2,convolved_speech_data2,mixed_signal) :\n",
        "  plt.subplot(3,1,1)\n",
        "  plt.subplots_adjust(hspace=1,wspace=5)\n",
        "  plt.title('Room Filter-1')\n",
        "  plt.plot(np.arange(0,80000),h1[:80000])\n",
        "  plt.subplot(3,1,2)\n",
        "  plt.title('Raw Source-1')\n",
        "  plt.plot(s1)\n",
        "  plt.subplot(3,1,3)\n",
        "  plt.title('Convolved Source-1 with Filter-1')\n",
        "  plt.plot(convolved_speech_data1)\n",
        "  plt.savefig('/content/drive/MyDrive/MajorProject/signal1.png')\n",
        "  plt.close()\n",
        "\n",
        "\n",
        "  plt.subplot(3,1,1)\n",
        "  plt.subplots_adjust(hspace=1,wspace=5)\n",
        "  plt.title('Room Filter-1')\n",
        "  plt.plot(np.arange(0,80000),h2[:80000])\n",
        "  plt.subplot(3,1,2)\n",
        "  plt.title('Raw Source-1')\n",
        "  plt.plot(s2)\n",
        "  plt.subplot(3,1,3)\n",
        "  plt.title('Convolved Source-1 with Filter-1')\n",
        "  plt.plot(convolved_speech_data2)\n",
        "  plt.savefig('/content/drive/MyDrive/MajorProject/signal2.png')\n",
        "  plt.close()\n",
        "\n",
        "  \n",
        "  plt.plot(mixed_signal)\n",
        "  plt.title('Mixed Source-1 and Source-2')\n",
        "  plt.savefig('/content/drive/MyDrive/MajorProject/mixedsignal.png')\n",
        "  plt.close()\n",
        "\n",
        "\n",
        "mat1 = loadmat('/content/drive/MyDrive/MajorProject/45.mat')\n",
        "h1 = mat1['impulse_response'][:,0]\n",
        "fs1, s1 = wavefile.load('/content/drive/MyDrive/MajorProject/1_0a139a.wav')\n",
        "s1=np.reshape(s1,s1.size)\n",
        "convolved_speech_data1 = np.convolve(s1[:80000],h1[:5000])\n",
        "\n",
        "\n",
        "mat2 = loadmat('/content/drive/MyDrive/MajorProject/135.mat')\n",
        "fs2, s2 = wavefile.load('/content/drive/MyDrive/MajorProject/1_00bdad.wav')\n",
        "s2=np.reshape(s2,s2.size)\n",
        "h2 = mat2['impulse_response'][:,0]\n",
        "convolved_speech_data2 = np.convolve(s2[:80000],h2[:5000])\n",
        "\n",
        "#plotting and storing a sample signal\n",
        "mixed_signal = convolved_speech_data1+convolved_speech_data2\n",
        "#plot(h1,s1,convolved_speech_data1,h2,s2,convolved_speech_data2,mixed_signal)   \n",
        "\n",
        "\n",
        "#creating the dataset\n",
        "dataset={}\n",
        "for k1 in np.arange(0.0,1.02,0.02):\n",
        "  for k2 in np.arange(0.0,1.02,0.02):\n",
        "    mixed_signal = (k1*convolved_speech_data1) + (k2*convolved_speech_data2)\n",
        "    if k1==0 and k2==0:\n",
        "      #write('/content/drive/MyDrive/MajorProject/custom_dataset/'+'1_'+str(k1)+'_'+str(k2)+'.wav',fs2,mixed_signal.astype(np.float32))\n",
        "      dataset['0_'+str(round(k1,2))+'_'+str(round(k2,2))]=mixed_signal\n",
        "    elif k1==0 or k2==0:\n",
        "      #write('/content/drive/MyDrive/MajorProject/custom_dataset/'+'1_'+str(k1)+'_'+str(k2)+'.wav',fs2,mixed_signal.astype(np.float32))\n",
        "      dataset['1_'+str(round(k1,2))+'_'+str(round(k2,2))]=mixed_signal\n",
        "    else:\n",
        "      #write('/content/drive/MyDrive/MajorProject/custom_dataset/'+'2_'+str(k1)+'_'+str(k2)+'.wav',fs2,mixed_signal.astype(np.float32))\n",
        "      dataset['2_'+str(round(k1,2))+'_'+str(round(k2,2))]=mixed_signal\n",
        "\n",
        "df=pd.DataFrame.from_dict(dataset)\n",
        "df.to_csv('/content/drive/MyDrive/MajorProject/dataset.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xga-XQnKrzk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}